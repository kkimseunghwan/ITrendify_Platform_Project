from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.action_chains import ActionChains
from bs4 import BeautifulSoup
import time

# 크롬 드라이버 설정
service = Service(executable_path="C:/Users/rhian/Downloads/chromedriver-win64/chromedriver.exe")
driver = webdriver.Chrome(service=service)

# 메인 페이지 이동
url = "https://www.wanted.co.kr/wdlist/518"
driver.get(url)

# 페이지 로딩 대기
time.sleep(3)

# HTML 가져오기
html = driver.page_source
soup = BeautifulSoup(html, 'html.parser')

# a 태그 찾기
a_tags = soup.find_all("a", {"data-attribute-id": "position__click"})

# 페이지 자체가 아래쪽으로 스크롤 해야 목록이 더 나오는 형식이라 데이터를 더 확보하기 위한 시스템을 만들 필요가 있음.

for a in a_tags:
    try:
        href = a.get('href')
        if not href:
            continue  # href 없으면 스킵

        companyUrl = "https://www.wanted.co.kr" + href
        print()
        print("공고 URL ", companyUrl)

        # 공고 페이지 접속
        driver.get(companyUrl)

        # 페이지 로딩 대기.
        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.CLASS_NAME, 'wds-1y0suvb'))
        )
        
        # '상세 정보 더 보기' 버튼이 있으면 클릭 시도하기
        try:
            more_info_button = WebDriverWait(driver, 5).until(
                EC.element_to_be_clickable((By.XPATH, "//button[.//span[text()='상세 정보 더 보기']]"))
            )
            driver.execute_script("arguments[0].click();", more_info_button)  # JavaScript로 강제 클릭
            time.sleep(1)  # 클릭 후 로딩 대기 (짧게)
        except Exception as e:
            print("상세 정보 더 보기 버튼 없음 또는 클릭 실패:", e)

        # 다시 page_source 가져와서 파싱
        detail_soup = BeautifulSoup(driver.page_source, 'html.parser')
        
        companyName = detail_soup.find('strong', class_='CompanyInfo_CompanyInfo__name__sBeI6')
        title = detail_soup.find('h1', class_='wds-jtr30u')
        newPerson = detail_soup.find_all('span', class_='JobHeader_JobHeader__Tools__Company__Info__b9P4Y wds-rgovpd')
    
        print()
        print(companyName.text)
        print(title.text, newPerson[-1].text)

        # h3 찾기
        h3_tags = detail_soup.find_all('h3', class_='wds-1y0suvb')

        for h3 in h3_tags:
            if h3.text.strip() == "자격요건":
                parent_div = h3.find_parent('div')
                span_tag = parent_div.find('span', class_='wds-wcfcu3')

                if span_tag:
                    print("[자격요건]")
                    print(span_tag.get_text(separator="\n"))
            if h3.text.strip() == "우대사항":
                parent_div = h3.find_parent('div')
                span_tag = parent_div.find('span', class_='wds-wcfcu3')

                if span_tag:
                    print("[우대사항]")
                    print(span_tag.get_text(separator="\n"))
                break  # 데이터 찾은 뒤 이 페이지는 검사 끝

    except Exception as e:
        print(f"[오류 발생] {e}")
        continue

# 드라이버 종료
driver.quit()



'''
        self.job_roles = {
            872: "서버 개발자",
            10110: "소프트웨어 엔지니어",
            660: "자바 개발자",
            669: "프론트엔드 개발자",
            873: "웹 개발자",
            899: "파이썬 개발자",
            900: "C, C++ 개발자",
            1634: "머신러닝 엔지니어",
            655: "데이터 엔지니어",
            665: "시스템 관리자",
            677: "안드로이드 개발자",
            895: "Node.js 개발자",
            676: "QA 엔지니어",
            1024: "데이터 사이언티스트",
            658: "임베디드 개발자",
            1025: "빅데이터 엔지니어",
            678: "IOS 개발자"
        }
'''